{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### podcast api part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cz_Gb81JJkQh"
      },
      "outputs": [],
      "source": [
        "from listennotes import podcast_api\n",
        "import pickle\n",
        "API_KEY = '06673b55481c47c3ac5636b2eddff44d' \n",
        "client = podcast_api.Client(api_key=API_KEY)\n",
        "INITIAL_NEXT_EPISODE_PUB_DATE = 1696380498000\n",
        "PODCAST_ID = '626ce14412af499d811d046990b2a34c'\n",
        "\n",
        "URL_DIR = \"C:/Users/ee527/Desktop/Big Data Analytics/final_project/podcast_url/\"\n",
        "TITLE_DIR = \"C:/Users/ee527/Desktop/Big Data Analytics/final_project/podcast_title/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8ED5snWRaXF",
        "outputId": "35876151-b62c-447b-f1b9-1e4f3da579aa"
      },
      "outputs": [],
      "source": [
        "days = lambda x: x*86400*1000*1\n",
        "INITIAL_NEXT_EPISODE_PUB_DATE = (days(1))\n",
        "n = 0\n",
        "\n",
        "while True:\n",
        "\n",
        "  INITIAL_NEXT_EPISODE_PUB_DATE = INITIAL_NEXT_EPISODE_PUB_DATE - (days(1))\n",
        "  response = client.fetch_podcast_by_id(id=PODCAST_ID,\n",
        "                                      next_episode_pub_date=INITIAL_NEXT_EPISODE_PUB_DATE,\n",
        "                                      sort='newest_first'\n",
        "                                      )\n",
        "  response_json = response.json()\n",
        "  \n",
        "  \n",
        "  # start process episode json here(suppose to have 10 episodes in one loop):\n",
        "  \n",
        "  episode_lst = response_json['episodes']\n",
        "  \n",
        "  print(len(episode_lst))\n",
        "  \n",
        "  audio_lst = []\n",
        "  audio_ep_num_lst = []\n",
        "  \n",
        "  for i in range(len(episode_lst)):\n",
        "    \n",
        "    title = episode_lst[i]['title']\n",
        "    \n",
        "    audio_url = episode_lst[i]['audio']\n",
        "    audio_lst.append(audio_url)\n",
        "    ep_num = title\n",
        "    audio_ep_num_lst.append(ep_num)\n",
        "    \n",
        "  \n",
        "  # save 10 episodes into a picke chunck\n",
        "  \n",
        "  fname = f'{n}.pkl'\n",
        "  \n",
        "  with open(URL_DIR + fname, 'wb') as f:\n",
        "      pickle.dump(audio_lst, f)\n",
        "      \n",
        "  with open(TITLE_DIR + fname, 'wb') as f2:\n",
        "      pickle.dump(audio_ep_num_lst, f2)\n",
        "      \n",
        "  \n",
        "  n+=1\n",
        "\n",
        "  print('next episode pub date', response_json['next_episode_pub_date'])\n",
        "  if response_json['next_episode_pub_date'] is None:\n",
        "    \n",
        "    print(\"end fetching podcaast\")\n",
        "    break\n",
        "  \n",
        "  else:\n",
        "    \n",
        "    INITIAL_NEXT_EPISODE_PUB_DATE = response_json['next_episode_pub_date']\n",
        "\n",
        "\n",
        "  print()\n",
        "\n",
        "  foo = [x['title'] for x in response_json['episodes']]\n",
        "  for i in foo:\n",
        "    print(i)\n",
        "    \n",
        "  print(\"==========================================================\")\n",
        "  \n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(audio_lst)\n",
        "print(audio_ep_num_lst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Whisper part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1.0+cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "import whisper\n",
        "import os\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "print(torch.__version__)\n",
        "device = torch.device('cuda')\n",
        "model = whisper.load_model(name=\"base\", device=device)\n",
        "\n",
        "URL_DIR = \"C:/Users/ee527/Desktop/Big Data Analytics/final_project/podcast_url/\"\n",
        "TITLE_DIR = \"C:/Users/ee527/Desktop/Big Data Analytics/final_project/podcast_title/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['https://www.listennotes.com/e/p/1671ec42ca694a219471bb939e729541/', 'https://www.listennotes.com/e/p/6163d428d0cb42a5b38e720203a12f20/', 'https://www.listennotes.com/e/p/46a32f6f62a649308617d211d0a2af0b/']\n",
            "['The Manhattan Arraignment', 'The First Indictment', 'Prosecuting Donald Trump: A Primer']\n",
            "\n",
            "The Manhattan Arraignment runtime: 357.34820318222046\n",
            "The First Indictment runtime: 127.85262036323547\n",
            "Prosecuting Donald Trump: A Primer runtime: 262.0648376941681\n"
          ]
        }
      ],
      "source": [
        "# read pickle file to get podcast url\n",
        "\n",
        "pkl_number = 5\n",
        "TRANSCRIBE_DIR = \"C:/Users/ee527/Desktop/Big Data Analytics/final_project/podcast_transcript/5/\"\n",
        "\n",
        "with open(URL_DIR + f\"{pkl_number}.pkl\", 'rb') as f:\n",
        "        \n",
        "        audio_url_lst = pickle.load(f)\n",
        "        \n",
        "print(audio_url_lst)\n",
        "\n",
        "with open(TITLE_DIR + f\"{pkl_number}.pkl\", 'rb') as f:\n",
        "        \n",
        "        audio_episode_num_lst = pickle.load(f)\n",
        "        \n",
        "print(audio_episode_num_lst)\n",
        "\n",
        "print()\n",
        "\n",
        "for i in range(len(audio_url_lst)):\n",
        "        \n",
        "    cleaned_title = re.sub(r'[^a-zA-Z0-9\\s]', '', audio_episode_num_lst[i])\n",
        "   \n",
        "    txt_path = TRANSCRIBE_DIR + cleaned_title + \".txt\"\n",
        "    \n",
        "\n",
        "    start = time.time()\n",
        "    result = model.transcribe(audio_url_lst[i])\n",
        "    end = time.time()\n",
        "\n",
        "    print(f\"{audio_episode_num_lst[i]} runtime:\", end-start)\n",
        "    \n",
        "    # write into txt file\n",
        "\n",
        "    with open(txt_path, 'w') as f:\n",
        "            f.write(result['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
